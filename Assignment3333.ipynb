{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Wine Quality Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1. Importing the necessary libraries:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import model_selection ,datasets, svm, metrics"
   ]
  },
  {
   "source": [
    "### 2. Loading the wine dataset:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = datasets.load_wine(return_X_y=True) #splitting the data into x (features) and y (targets)."
   ]
  },
  {
   "source": [
    "### 3. Performing K-fold cross-validation:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a function that splits the data into train and test splits using indices.\n",
    "def kfold_train_test_split(x, y, train_indices, test_indices):\n",
    "  return x[train_indices], x[test_indices], y[train_indices], y[test_indices]\n",
    "  \n",
    "scores = [] #Defining an empty array to store the model scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_s_k_fold = model_selection.StratifiedShuffleSplit(n_splits=10, random_state=42) #spliting the data into 10 splits, with 9 of them being for training and 1 for testing for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looping through the splitted data that was splitted using the StratisfiedShuffleSplit().\n",
    "\n",
    "for train_indices, test_indices in s_s_k_fold.split(x, y): # y is used  for stratification. \n",
    "  \n",
    "  #Spliting the data using the defined function (kfold_train_test_split).\n",
    "  x_train, x_test, y_train, y_test = kfold_train_test_split(x, y, train_indices, test_indices)"
   ]
  },
  {
   "source": [
    "### 4. Defining the classification model:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=42,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "svc = svm.SVC(random_state=42) #Using support vector machines classifier (SVC), as it is a classification problem.\n",
    "svc.fit(x_train, y_train) #Training the model"
   ]
  },
  {
   "source": [
    "### 5. Training the model and making predictions without tuning the hyperparameters:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(x_test) #Making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred) #Calculating the accuracy score, (recall and precision metrics will not be calculated as this a multiclass problem).\n",
    "\n",
    "scores_dict = {\"accuracy\": accuracy} #Making a dictionary and fit the accuracy scores.\n",
    "scores.append(scores_dict) #Adding the scores dictionary into the previously defined empty array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   accuracy  Accuracy\n",
       "0  0.555556       NaN\n",
       "1  0.555556       NaN\n",
       "2       NaN  0.555556\n",
       "3       NaN  0.555556\n",
       "4  0.555556       NaN\n",
       "5  0.555556       NaN\n",
       "6  0.944444       NaN\n",
       "7  0.555556       NaN"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.555556</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.555556</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>NaN</td>\n      <td>0.555556</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>NaN</td>\n      <td>0.555556</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.555556</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.555556</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.944444</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.555556</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(scores) #Converting the array into a dataframe for an organized display.\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model's mean accuracy value: accuracy    0.620370\nAccuracy    0.555556\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's mean accuracy value:\", scores_df.mean()) #Printing the mean value for the accuracies of the 10 splits."
   ]
  },
  {
   "source": [
    "### 6. Performing hyperparameters tuning:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the hyperparameters to be tuned and define a range for the values.\n",
    "h_params = {'kernel': ['sigmoid','linear', 'rbf'], 'C': [0.1,10,100], 'gamma': [0.001, 0.01, 0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the automatic GridSearch() function to test every parameter and give us the best ones.\n",
    "auto_gs = model_selection.GridSearchCV(svc, h_params, cv=s_s_k_fold, refit=\"accuracy\", verbose=2) \n",
    "#verbose is set to 2 to display the training logs, we can also set it to 1 for just a describtion of the training and 0 for just the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=10, random_state=42, test_size=None,\n",
       "            train_size=None),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=42, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.1, 10, 100], 'gamma': [0.001, 0.01, 0.1],\n",
       "                         'kernel': ['sigmoid', 'linear', 'rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit='accuracy',\n",
       "             return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "#Fitting the grid search operation onto our data\n",
    "auto_gs.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Hyperparameters: {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}\nBest Score (Accuracy):  0.95\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters:\", auto_gs.best_params_) #To display the best values of the hyperparameters.\n",
    "print(\"Best Score (Accuracy): \", auto_gs.best_score_) #To display the accuracy associated with the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}